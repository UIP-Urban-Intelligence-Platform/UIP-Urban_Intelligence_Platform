#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""Computer Vision Analysis Agent.

UIP - Urban Intelligence Platform
Copyright (C) 2025 UIP Team

SPDX-License-Identifier: MIT

Module: src.agents.analytics.cv_analysis_agent
Project: UIP - Urban Intelligence Platform
Author: Nguyen Nhat Quang <nguyennhatquang522004@gmail.com>
Created: 2025-11-21
Version: 1.0.0
License: MIT

Description:
    Performs object detection and traffic metrics calculation using YOLOX deep learning model.
    Detects vehicles from camera images and generates ItemFlowObserved NGSI-LD entities.

Core Features:
    - Asynchronous batch image downloading with connection pooling
    - YOLOX object detection (COCO dataset: cars, motorbikes, buses, trucks)
    - DenseNet-based accident detection (binary classification)
    - Vehicle classification and counting per image
    - Traffic metrics calculation (intensity, occupancy, estimated speed)
    - NGSI-LD ItemFlowObserved entity generation
    - Performance monitoring and error handling
    - Domain-agnostic design via YAML configuration

LICENSE INFORMATION:
    This module uses YOLOX (Apache-2.0) and DenseNet via timm (Apache-2.0).
    The entire project is MIT licensed and fully open source.

    See LICENSE file for full MIT license text.

Dependencies:
    - yolox: YOLOX object detection (Apache-2.0 license by Megvii)
    - timm>=0.9.0: PyTorch Image Models for DenseNet accident detection
    - opencv-python>=4.0: Image processing
    - aiohttp>=3.8: Async HTTP client
    - Pillow>=9.0: Image manipulation
    - torch>=1.7: PyTorch deep learning framework

Configuration:
    Requires cv_config.yaml containing:
    - model_path: Path to YOLOX weights file
    - confidence_threshold: Detection confidence (default: 0.25)
    - vehicle_classes: COCO class IDs for vehicles
    - batch_size: Images per batch (default: 10)
    - timeout: HTTP timeout in seconds

Examples:
    >>> from src.agents.analytics import CVAnalysisAgent
    >>>
    >>> config = {'model_path': 'models/yolox_s.pth', 'confidence': 0.25}
    >>> agent = CVAnalysisAgent(config)
    >>>
    >>> cameras = [{'id': 'CAM001', 'image_url': 'http://...'}]
    >>> observations = agent.analyze_batch(cameras)
    >>> print(observations[0]['vehicleCount'])

Performance:
    - Processing speed: ~15-40 images/second (GPU)
    - Batch processing reduces overhead by 3-5x
    - Memory usage: ~1.5GB GPU VRAM for YOLOX-S model

References:
    - YOLOX Documentation: https://github.com/Megvii-BaseDetection/YOLOX
    - COCO Dataset: https://cocodataset.org/
    - timm (PyTorch Image Models): https://github.com/huggingface/pytorch-image-models
    - ItemFlowObserved Schema: https://github.com/smart-data-models/dataModel.Transportation
"""

import asyncio
import io
import json
import logging
import os
import sys
import time
from dataclasses import asdict, dataclass, field
from datetime import datetime
from enum import Enum
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple
from urllib.parse import urlparse

# Fix Windows asyncio event loop issue (must be before aiohttp import)
if sys.platform == 'win32':
    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())

import aiohttp
import yaml
from PIL import Image

# Import environment variable expansion helper
from src.core.config_loader import expand_env_var

# MongoDB integration (optional)
try:
    from src.utils.mongodb_helper import get_mongodb_helper

    MONGODB_AVAILABLE = True
except ImportError:
    MONGODB_AVAILABLE = False
    get_mongodb_helper = None

# Stellio real-time publisher
import requests as http_requests

class StellioRealtimePublisher:
    """Real-time publisher to push entities to Stellio immediately after detection."""
    
    def __init__(self, stellio_url: str = None):
        self.stellio_url = stellio_url or os.environ.get('STELLIO_URL', 'http://localhost:8080')
        self.session = None
        self._enabled = True
        
    def _get_session(self):
        """Get or create HTTP session."""
        if self.session is None:
            self.session = http_requests.Session()
            self.session.headers.update({
                'Content-Type': 'application/ld+json',
                'Accept': 'application/ld+json'
            })
        return self.session
    
    def publish_entities_batch(self, entities: List[Dict[str, Any]], entity_type: str = "ItemFlowObserved") -> Tuple[int, int]:
        """
        Publish entities to Stellio immediately using batch upsert.
        
        Args:
            entities: List of NGSI-LD entities
            entity_type: Type of entity for logging
            
        Returns:
            Tuple of (successful_count, failed_count)
        """
        if not entities or not self._enabled:
            return 0, 0
            
        try:
            session = self._get_session()
            url = f"{self.stellio_url}/ngsi-ld/v1/entityOperations/upsert"
            
            response = session.post(url, json=entities, params={'options': 'update'}, timeout=30)
            
            if response.status_code in [200, 201, 204]:
                logger.info(f"üì§ REAL-TIME: Published {len(entities)} {entity_type} entities to Stellio")
                return len(entities), 0
            elif response.status_code == 207:
                # Partial success
                logger.warning(f"üì§ REAL-TIME: Partial success publishing {entity_type} to Stellio")
                return len(entities) // 2, len(entities) // 2
            else:
                logger.warning(f"üì§ REAL-TIME: Failed to publish {entity_type}: {response.status_code}")
                return 0, len(entities)
                
        except Exception as e:
            logger.warning(f"üì§ REAL-TIME: Stellio publish error (non-critical): {e}")
            return 0, len(entities)
    
    def publish_single_entity(self, entity: Dict[str, Any]) -> bool:
        """Publish single entity immediately."""
        success, _ = self.publish_entities_batch([entity], entity.get('type', 'Entity'))
        return success > 0

# Global real-time publisher instance
_realtime_publisher: Optional[StellioRealtimePublisher] = None

def get_realtime_publisher() -> StellioRealtimePublisher:
    """Get singleton real-time publisher."""
    global _realtime_publisher
    if _realtime_publisher is None:
        _realtime_publisher = StellioRealtimePublisher()
    return _realtime_publisher

# Configure logging
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


class DetectionStatus(Enum):
    """Detection status enumeration"""

    SUCCESS = "success"
    FAILED = "failed"
    NO_DETECTIONS = "no_detections"
    INVALID_IMAGE = "invalid_image"
    TIMEOUT = "timeout"


@dataclass
class Detection:
    """Single object detection result"""

    class_id: int
    class_name: str
    confidence: float
    bbox: List[float]  # [x1, y1, x2, y2]

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary"""
        return asdict(self)


@dataclass
class ImageAnalysisResult:
    """Result of analyzing a single image"""

    camera_id: str
    status: DetectionStatus
    timestamp: str
    detections: List[Detection] = field(default_factory=list)
    vehicle_count: int = 0
    person_count: int = 0
    processing_time: float = 0.0
    error_message: Optional[str] = None
    image_url: Optional[str] = None
    metadata: Optional[Dict[str, Any]] = None

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary"""
        result_dict = {
            "camera_id": self.camera_id,
            "status": self.status.value,
            "timestamp": self.timestamp,
            "detections": [d.to_dict() for d in self.detections],
            "vehicle_count": self.vehicle_count,
            "person_count": self.person_count,
            "processing_time": self.processing_time,
            "error_message": self.error_message,
            "image_url": self.image_url,
        }
        if self.metadata:
            result_dict["metadata"] = self.metadata
        return result_dict


@dataclass
class TrafficMetrics:
    """Traffic metrics calculated from detections"""

    vehicle_count: int
    intensity: float  # 0.0-1.0 (vehicles/max_vehicles)
    occupancy: float  # 0.0-1.0 (same as intensity)
    average_speed: float  # km/h (estimated)
    congestion_level: str  # "free", "moderate", "congested"

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary"""
        return asdict(self)


class CVConfig:
    """Configuration loader for CV analysis agent"""

    def __init__(self, config_path: str = "config/cv_config.yaml"):
        """
        Initialize configuration loader

        Args:
            config_path: Path to YAML configuration file
        """
        self.config_path = config_path
        self.config: Dict[str, Any] = {}
        self.load()

    def load(self) -> None:
        """Load configuration from YAML file"""
        try:
            with open(self.config_path, "r", encoding="utf-8") as f:
                self.config = yaml.safe_load(f)
            # Expand environment variables like ${STELLIO_URL:-default}
            self.config = expand_env_var(self.config)
            logger.info(f"Loaded CV configuration from {self.config_path}")
        except FileNotFoundError:
            raise FileNotFoundError(f"Configuration file not found: {self.config_path}")
        except yaml.YAMLError as e:
            raise ValueError(f"Invalid YAML in configuration file: {e}")

    def get_model_config(self) -> Dict[str, Any]:
        """Get model configuration"""
        return self.config.get("cv_analysis", {}).get("model", {})

    def get_vehicle_classes(self) -> List[str]:
        """Get vehicle classes to detect"""
        return self.config.get("cv_analysis", {}).get("vehicle_classes", [])

    def get_person_classes(self) -> List[str]:
        """Get person classes to detect"""
        return self.config.get("cv_analysis", {}).get("person_classes", [])

    def get_metrics_config(self) -> Dict[str, Any]:
        """Get metrics configuration"""
        return self.config.get("cv_analysis", {}).get("metrics", {})

    def get_batch_size(self) -> int:
        """Get batch size for parallel processing"""
        return self.config.get("cv_analysis", {}).get("batch_size", 20)

    def get_timeout(self) -> int:
        """Get HTTP timeout"""
        return self.config.get("cv_analysis", {}).get("timeout", 10)

    def get_output_config(self) -> Dict[str, Any]:
        """Get output configuration"""
        return self.config.get("cv_analysis", {}).get("output", {})

    def get_image_config(self) -> Dict[str, Any]:
        """Get image processing configuration"""
        return self.config.get("cv_analysis", {}).get("image", {})

    # Citizen verification configuration
    @property
    def citizen_verification_enabled(self) -> bool:
        """Check if citizen verification is enabled"""
        return (
            self.config.get("cv_analysis", {})
            .get("citizen_verification", {})
            .get("enabled", False)
        )

    @property
    def citizen_verification_poll_interval(self) -> int:
        """Get citizen verification poll interval in seconds"""
        return (
            self.config.get("cv_analysis", {})
            .get("citizen_verification", {})
            .get("poll_interval", 30)
        )

    @property
    def citizen_verification_stellio_url(self) -> str:
        """Get Stellio URL for citizen verification from config (env vars already expanded)"""
        return (
            self.config.get("cv_analysis", {})
            .get("citizen_verification", {})
            .get("stellio_url", "http://localhost:8080")
        )

    @property
    def citizen_verification_query(self) -> str:
        """Get Stellio query for unverified reports"""
        return (
            self.config.get("cv_analysis", {})
            .get("citizen_verification", {})
            .get("query", "type=CitizenObservation&q=aiVerified==false")
        )

    @property
    def citizen_verification_max_batch(self) -> int:
        """Get max reports per batch"""
        return (
            self.config.get("cv_analysis", {})
            .get("citizen_verification", {})
            .get("max_reports_per_batch", 10)
        )

    @property
    def citizen_verification_rules(self) -> Dict[str, Any]:
        """Get verification rules per report type"""
        return (
            self.config.get("cv_analysis", {})
            .get("citizen_verification", {})
            .get("verification_rules", {})
        )

    @property
    def citizen_verification_scoring(self) -> Dict[str, float]:
        """Get scoring algorithm weights"""
        return (
            self.config.get("cv_analysis", {})
            .get("citizen_verification", {})
            .get("scoring", {})
        )

    @property
    def citizen_verification_update_patch_stellio(self) -> bool:
        """Check if PATCH to Stellio is enabled"""
        return (
            self.config.get("cv_analysis", {})
            .get("citizen_verification", {})
            .get("update", {})
            .get("patch_stellio", True)
        )

    @property
    def citizen_verification_update_set_verified_status(self) -> bool:
        """Check if status update is enabled"""
        return (
            self.config.get("cv_analysis", {})
            .get("citizen_verification", {})
            .get("update", {})
            .get("set_verified_status", True)
        )


class YOLOXDetector:
    """
    YOLOX object detector wrapper (Apache-2.0 License)

    YOLOX is an anchor-free version of YOLO by Megvii, offering better performance
    and simpler design. This detector is fully MIT-compatible.

    License: Apache-2.0 (https://github.com/Megvii-BaseDetection/YOLOX)
    """

    # COCO class names mapping (same as YOLO - 80 classes)
    COCO_CLASSES = {
        0: "person",
        1: "bicycle",
        2: "car",
        3: "motorcycle",
        4: "airplane",
        5: "bus",
        6: "train",
        7: "truck",
        8: "boat",
        9: "traffic light",
        10: "fire hydrant",
        11: "stop sign",
        12: "parking meter",
        13: "bench",
        14: "bird",
        15: "cat",
        16: "dog",
        17: "horse",
        18: "sheep",
        19: "cow",
        20: "elephant",
        21: "bear",
        22: "zebra",
        23: "giraffe",
        24: "backpack",
        25: "umbrella",
        26: "handbag",
        27: "tie",
        28: "suitcase",
        29: "frisbee",
        30: "skis",
        31: "snowboard",
        32: "sports ball",
        33: "kite",
        34: "baseball bat",
        35: "baseball glove",
        36: "skateboard",
        37: "surfboard",
        38: "tennis racket",
        39: "bottle",
        40: "wine glass",
        41: "cup",
        42: "fork",
        43: "knife",
        44: "spoon",
        45: "bowl",
        46: "banana",
        47: "apple",
        48: "sandwich",
        49: "orange",
        50: "broccoli",
        51: "carrot",
        52: "hot dog",
        53: "pizza",
        54: "donut",
        55: "cake",
        56: "chair",
        57: "couch",
        58: "potted plant",
        59: "bed",
        60: "dining table",
        61: "toilet",
        62: "tv",
        63: "laptop",
        64: "mouse",
        65: "remote",
        66: "keyboard",
        67: "cell phone",
        68: "microwave",
        69: "oven",
        70: "toaster",
        71: "sink",
        72: "refrigerator",
        73: "book",
        74: "clock",
        75: "vase",
        76: "scissors",
        77: "teddy bear",
        78: "hair drier",
        79: "toothbrush",
    }

    # Map common names to COCO class IDs
    CLASS_NAME_TO_ID = {
        "person": 0,
        "car": 2,
        "motorcycle": 3,
        "motorbike": 3,  # Alias for motorcycle
        "bus": 5,
        "truck": 7,
    }

    def __init__(self, config: Dict[str, Any]):
        """
        Initialize YOLOX detector

        Args:
            config: Model configuration dictionary
                - weights: Path to YOLOX weights (.pth file)
                - confidence: Detection confidence threshold
                - iou_threshold: NMS IoU threshold
                - device: 'cpu' or 'cuda'
                - max_det: Maximum detections per image
                - model_name: YOLOX model variant (yolox-s, yolox-m, yolox-l, yolox-x)
        """
        self.config = config
        self.model = None
        self.exp = None
        self.device = config.get("device", "cpu")
        self.confidence = config.get("confidence", 0.5)
        self.iou_threshold = config.get("iou_threshold", 0.45)
        self.max_det = config.get("max_det", 300)
        self.model_name = config.get("model_name", "yolox-s")
        self.test_size = (640, 640)  # Default input size

        # Load model
        self._load_model()

    def _load_model(self) -> None:
        """Load YOLOX model"""
        try:
            import torch
            from yolox.data.data_augment import ValTransform
            from yolox.exp import get_exp
            from yolox.utils import postprocess

            # Store for later use
            self.postprocess = postprocess
            self.preproc = ValTransform(legacy=False)

            # Get experiment configuration
            exp_name = self.model_name.replace("yolox-", "yolox_")
            self.exp = get_exp(None, exp_name)
            self.test_size = self.exp.test_size

            # Load model
            self.model = self.exp.get_model()

            # Load weights if provided
            weights = self.config.get("weights")
            if weights and Path(weights).exists():
                ckpt = torch.load(weights, map_location=self.device)
                if "model" in ckpt:
                    self.model.load_state_dict(ckpt["model"])
                else:
                    self.model.load_state_dict(ckpt)
                logger.info(f"Loaded YOLOX weights: {weights}")

            # Move to device and set eval mode
            if self.device == "cuda" and torch.cuda.is_available():
                self.model.cuda()
            self.model.eval()

            logger.info(
                f"‚úÖ Loaded YOLOX model: {self.model_name} on device: {self.device}"
            )
            logger.info(f"   License: Apache-2.0 (MIT compatible)")

        except ImportError:
            logger.warning("YOLOX not installed - using mock detector for testing")
            logger.info("Install with: pip install yolox")
            self.model = None
        except Exception as e:
            logger.error(f"Failed to load YOLOX model: {e}")
            self.model = None

    def detect(self, image: Image.Image) -> List[Detection]:
        """
        Perform object detection on image

        Args:
            image: PIL Image object

        Returns:
            List of Detection objects
        """
        if self.model is None:
            # Mock detection for testing when YOLOX not available
            return self._mock_detect(image)

        try:
            import numpy as np
            import torch

            # Ensure image is RGB (some cameras return grayscale)
            if image.mode != "RGB":
                image = image.convert("RGB")

            # Convert PIL to numpy array (RGB)
            img = np.array(image)

            # Validate image dimensions (must be 3D: height, width, channels)
            if img.ndim != 3:
                logger.warning(f"Invalid image dimensions: {img.ndim}D, expected 3D")
                return []

            # Preprocess
            img_info = {"height": img.shape[0], "width": img.shape[1]}
            ratio = min(
                self.test_size[0] / img.shape[0], self.test_size[1] / img.shape[1]
            )
            img_info["ratio"] = ratio

            # Apply preprocessing
            img_preprocessed, _ = self.preproc(img, None, self.test_size)
            img_tensor = torch.from_numpy(img_preprocessed).unsqueeze(0).float()

            if self.device == "cuda":
                img_tensor = img_tensor.cuda()

            # Run inference
            with torch.no_grad():
                outputs = self.model(img_tensor)
                outputs = self.postprocess(
                    outputs,
                    num_classes=self.exp.num_classes,
                    conf_thre=self.confidence,
                    nms_thre=self.iou_threshold,
                )

            # Parse results
            detections = []
            if outputs[0] is not None:
                output = outputs[0].cpu().numpy()

                # Limit detections
                output = output[: self.max_det]

                for det in output:
                    # Format: [x1, y1, x2, y2, obj_conf, class_conf, class_id]
                    x1, y1, x2, y2 = det[:4] / ratio  # Scale back to original size
                    obj_conf = det[4]
                    class_conf = det[5]
                    class_id = int(det[6])

                    confidence = float(obj_conf * class_conf)
                    class_name = self.COCO_CLASSES.get(class_id, f"class_{class_id}")

                    detections.append(
                        Detection(
                            class_id=class_id,
                            class_name=class_name,
                            confidence=confidence,
                            bbox=[float(x1), float(y1), float(x2), float(y2)],
                        )
                    )

            return detections

        except Exception as e:
            logger.error(f"Detection failed: {e}")
            return []

    def _mock_detect(self, image: Image.Image) -> List[Detection]:
        """
        Mock detection for testing

        Args:
            image: PIL Image object

        Returns:
            List of mock Detection objects
        """
        # Generate mock detections based on image dimensions
        width, height = image.size
        mock_detections = [
            Detection(
                class_id=2,
                class_name="car",
                confidence=0.85,
                bbox=[width * 0.1, height * 0.2, width * 0.3, height * 0.6],
            ),
            Detection(
                class_id=2,
                class_name="car",
                confidence=0.78,
                bbox=[width * 0.4, height * 0.3, width * 0.6, height * 0.7],
            ),
            Detection(
                class_id=3,
                class_name="motorcycle",
                confidence=0.92,
                bbox=[width * 0.7, height * 0.4, width * 0.85, height * 0.75],
            ),
        ]
        return mock_detections


# ============================================================================
# Accident Detection (DETR-based - Apache-2.0 License)
# ============================================================================


class AccidentDetector:
    """
    DETR-based accident detection from camera images.

    Uses the hilmantm/detr-traffic-accident-detection model from HuggingFace,
    a DETR (DEtection TRansformer) model trained on 3200+ accident images.

    Model: hilmantm/detr-traffic-accident-detection
    Source: https://huggingface.co/hilmantm/detr-traffic-accident-detection
    License: Apache-2.0 (MIT compatible, fully open source)

    Detection Classes:
        - accident: General accident/crash detection
        - vehicle: Vehicle detection (to avoid false positives in traffic)

    The model uses transformer architecture with ResNet-50 backbone,
    providing state-of-the-art accident detection with NMS post-processing.

    Example:
        ```python
        config = {
            'model_name': 'hilmantm/detr-traffic-accident-detection',
            'confidence': 0.5,
            'device': 'cpu'
        }
        detector = AccidentDetector(config)
        accidents = detector.detect(camera_image)
        if accidents:
            severity = detector.estimate_severity(accidents[0])
        ```
    """

    def __init__(self, config: Dict[str, Any]):
        """
        Initialize accident detector with DETR model from HuggingFace.

        Args:
            config: Accident detection configuration
                - model_name: HuggingFace model ID (default: hilmantm/detr-traffic-accident-detection)
                - confidence: Detection confidence threshold
                - device: 'cpu' or 'cuda'
                - max_det: Maximum detections per image
        """
        self.config = config
        self.model = None
        self.processor = None
        self.device = config.get("device", "cpu")
        self.confidence = config.get("confidence", 0.4)
        self.max_det = config.get("max_det", 10)
        self.model_name = config.get(
            "model_name", "hilmantm/detr-traffic-accident-detection"
        )

        # Severity thresholds
        self.severity_thresholds = config.get(
            "severity_thresholds", {"minor": 0.4, "moderate": 0.6, "severe": 0.8}
        )

        # Load model
        self._load_model()

    def _load_model(self) -> None:
        """Load DETR accident detection model from HuggingFace."""
        try:
            import torch
            from transformers import AutoImageProcessor, AutoModelForObjectDetection

            # Load processor and model from HuggingFace
            self.processor = AutoImageProcessor.from_pretrained(self.model_name)
            self.model = AutoModelForObjectDetection.from_pretrained(self.model_name)

            # Move to device
            if self.device == "cuda":
                import torch

                if torch.cuda.is_available():
                    self.model = self.model.cuda()

            self.model.eval()

            logger.info(f"‚úÖ Loaded DETR accident detection model: {self.model_name}")
            logger.info(f"   Device: {self.device}")
            logger.info(f"   Confidence threshold: {self.confidence}")
            logger.info(f"   License: Apache-2.0 (MIT compatible)")

        except ImportError as e:
            logger.warning(
                f"transformers not installed - accident detection unavailable: {e}"
            )
            logger.info("Install with: pip install transformers")
            self.model = None
            self.processor = None
        except Exception as e:
            logger.error(f"Failed to load DETR accident detection model: {e}")
            self.model = None
            self.processor = None

    def detect(self, image: Image.Image) -> List[Detection]:
        """
        Detect accidents in image using DETR transformer model.

        Args:
            image: PIL Image

        Returns:
            List of accident detections (class_name='accident' only)
        """
        if self.model is None or self.processor is None:
            return []

        try:
            import torch

            # Ensure image is RGB (some cameras return grayscale)
            if image.mode != "RGB":
                image = image.convert("RGB")

            # Prepare image for model
            inputs = self.processor(images=image, return_tensors="pt")

            # Move to device
            if self.device == "cuda" and torch.cuda.is_available():
                inputs = {k: v.cuda() for k, v in inputs.items()}

            # Run inference
            with torch.no_grad():
                outputs = self.model(**inputs)

            # Post-process: get detections with bounding boxes
            target_sizes = torch.tensor([image.size[::-1]])  # (height, width)
            if self.device == "cuda" and torch.cuda.is_available():
                target_sizes = target_sizes.cuda()

            results = self.processor.post_process_object_detection(
                outputs, target_sizes=target_sizes, threshold=self.confidence
            )[0]

            # Parse results - filter for accident class only
            detections = []
            for score, label_id, box in zip(
                results["scores"], results["labels"], results["boxes"]
            ):
                score = score.item()
                label_id = label_id.item()
                bbox = box.tolist()

                # Get class name from model config
                class_name = self.model.config.id2label.get(
                    label_id, f"class_{label_id}"
                )

                # Only keep accident detections (not vehicles)
                if "accident" in class_name.lower():
                    detection = Detection(
                        class_id=label_id,
                        class_name=class_name,
                        confidence=score,
                        bbox=bbox,
                    )
                    detections.append(detection)

            # Limit to max_det
            detections = detections[: self.max_det]

            if detections:
                logger.info(f"üö® Detected {len(detections)} accident(s) in image")
                for det in detections:
                    severity = self.estimate_severity(det)
                    logger.info(
                        f"   - {det.class_name}: {det.confidence:.2f} ({severity})"
                    )

            return detections

        except Exception as e:
            logger.error(f"Accident detection failed: {e}")
            return []

    def estimate_severity(self, detection: Detection) -> str:
        """
        Estimate accident severity based on detection confidence.

        Args:
            detection: Accident detection

        Returns:
            Severity level: 'minor', 'moderate', or 'severe'
        """
        conf = detection.confidence

        if conf >= self.severity_thresholds["severe"]:
            return "severe"
        elif conf >= self.severity_thresholds["moderate"]:
            return "moderate"
        else:
            return "minor"

    def is_enabled(self) -> bool:
        """Check if accident detection is enabled and model loaded."""
        return self.model is not None and self.processor is not None


class ImageDownloader:
    """
    Advanced async image downloader with comprehensive optimization strategies

    Features:
    - Connection pooling with keepalive
    - DNS caching
    - Exponential backoff retry strategy
    - Browser-like headers
    - Local image caching
    - Compression support
    - SSL/TLS optimization
    """

    def __init__(self, config: Dict[str, Any]):
        """
        Initialize optimized image downloader

        Args:
            config: Full cv_analysis configuration dictionary with connection and cache settings
        """
        # Basic settings
        self.timeout = config.get("timeout", 180)
        self.max_retries = config.get("max_retries", 5)
        self.retry_delay = config.get("retry_delay", 10)

        # Connection settings
        conn_config = config.get("connection", {})
        self.pool_size = conn_config.get("pool_size", 10)
        self.pool_ttl = conn_config.get("pool_ttl", 300)
        self.keepalive_timeout = conn_config.get("keepalive_timeout", 60)
        self.dns_cache_ttl = conn_config.get("dns_cache_ttl", 600)
        self.use_exponential_backoff = conn_config.get("exponential_backoff", True)
        self.backoff_factor = conn_config.get("backoff_factor", 2.0)
        self.max_retry_delay = conn_config.get("max_retry_delay", 60)
        self.use_browser_headers = conn_config.get("use_browser_headers", True)
        self.user_agent = conn_config.get(
            "user_agent", "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        )
        self.verify_ssl = conn_config.get("verify_ssl", True)
        self.ssl_timeout = conn_config.get("ssl_timeout", 30)
        self.follow_redirects = conn_config.get("follow_redirects", True)
        self.max_redirects = conn_config.get("max_redirects", 3)
        self.compress = conn_config.get("compress", True)

        # Cache settings
        cache_config = config.get("cache", {})
        self.cache_enabled = cache_config.get("enabled", True)
        self.cache_dir = Path(cache_config.get("directory", "data/cache/images"))
        self.cache_ttl_minutes = cache_config.get("ttl_minutes", 30)
        self.cache_max_size_mb = cache_config.get("max_size_mb", 500)
        self.cleanup_on_start = cache_config.get("cleanup_on_start", False)

        # Initialize cache
        if self.cache_enabled:
            self._init_cache()

        # Session will be created per batch
        self._connector = None
        self._session = None

    def _init_cache(self) -> None:
        """Initialize cache directory and cleanup if needed"""
        try:
            self.cache_dir.mkdir(parents=True, exist_ok=True)

            if self.cleanup_on_start:
                self._cleanup_old_cache()

            # Check cache size
            self._enforce_cache_size_limit()

            logger.info(f"Image cache initialized: {self.cache_dir}")
        except Exception as e:
            logger.warning(f"Failed to initialize cache: {e}. Caching disabled.")
            self.cache_enabled = False

    def _cleanup_old_cache(self) -> None:
        """Remove cache files older than TTL"""
        try:
            current_time = time.time()
            ttl_seconds = self.cache_ttl_minutes * 60
            removed_count = 0

            for cache_file in self.cache_dir.glob("*.jpg"):
                if current_time - cache_file.stat().st_mtime > ttl_seconds:
                    cache_file.unlink()
                    removed_count += 1

            if removed_count > 0:
                logger.info(f"Cleaned up {removed_count} old cache files")
        except Exception as e:
            logger.warning(f"Cache cleanup failed: {e}")

    def _enforce_cache_size_limit(self) -> None:
        """Enforce maximum cache size by removing oldest files"""
        try:
            # Calculate current cache size
            cache_files = list(self.cache_dir.glob("*.jpg"))
            total_size_mb = sum(f.stat().st_size for f in cache_files) / (1024 * 1024)

            if total_size_mb > self.cache_max_size_mb:
                # Sort by modification time (oldest first)
                cache_files.sort(key=lambda f: f.stat().st_mtime)

                # Remove oldest files until under limit
                removed_count = 0
                while total_size_mb > self.cache_max_size_mb and cache_files:
                    oldest = cache_files.pop(0)
                    size_mb = oldest.stat().st_size / (1024 * 1024)
                    oldest.unlink()
                    total_size_mb -= size_mb
                    removed_count += 1

                if removed_count > 0:
                    logger.info(
                        f"Removed {removed_count} cache files to enforce size limit"
                    )
        except Exception as e:
            logger.warning(f"Cache size enforcement failed: {e}")

    def _get_cache_key(self, url: str) -> str:
        """Generate cache key from URL"""
        import hashlib

        return hashlib.md5(url.encode()).hexdigest()

    def _get_cached_image(self, url: str) -> Optional[Image.Image]:
        """
        Retrieve image from cache if available and not expired

        Args:
            url: Image URL

        Returns:
            PIL Image object or None if not in cache or expired
        """
        if not self.cache_enabled:
            return None

        try:
            cache_key = self._get_cache_key(url)
            cache_file = self.cache_dir / f"{cache_key}.jpg"

            if not cache_file.exists():
                return None

            # Check if expired
            current_time = time.time()
            file_age = current_time - cache_file.stat().st_mtime
            ttl_seconds = self.cache_ttl_minutes * 60

            if file_age > ttl_seconds:
                # Expired, remove it
                cache_file.unlink()
                return None

            # Load and return cached image
            image = Image.open(cache_file)
            logger.debug(f"Cache HIT for URL: {url[:80]}...")
            return image

        except Exception as e:
            logger.debug(f"Cache read failed for {url[:80]}...: {e}")
            return None

    def _save_to_cache(self, url: str, image: Image.Image) -> None:
        """
        Save image to cache

        Args:
            url: Image URL
            image: PIL Image object
        """
        if not self.cache_enabled:
            return

        try:
            cache_key = self._get_cache_key(url)
            cache_file = self.cache_dir / f"{cache_key}.jpg"

            # Save as JPEG
            image.save(cache_file, "JPEG", quality=95)
            logger.debug(f"Cached image: {cache_file.name}")

        except Exception as e:
            logger.debug(f"Failed to cache image: {e}")

    def _get_headers(self) -> Dict[str, str]:
        """
        Generate browser-like HTTP headers

        Returns:
            Dictionary of HTTP headers
        """
        headers = {}

        if self.use_browser_headers:
            headers.update(
                {
                    "User-Agent": self.user_agent,
                    "Accept": "image/avif,image/webp,image/apng,image/svg+xml,image/*,*/*;q=0.8",
                    "Accept-Language": "en-US,en;q=0.9,vi;q=0.8",
                    "Accept-Encoding": (
                        "gzip, deflate, br" if self.compress else "identity"
                    ),
                    "Connection": "keep-alive",
                    "Sec-Fetch-Dest": "image",
                    "Sec-Fetch-Mode": "no-cors",
                    "Sec-Fetch-Site": "cross-site",
                    "Cache-Control": "no-cache",
                    "Pragma": "no-cache",
                }
            )

        return headers

    def _calculate_retry_delay(self, attempt: int) -> float:
        """
        Calculate retry delay with exponential backoff

        Args:
            attempt: Current attempt number (0-indexed)

        Returns:
            Delay in seconds
        """
        if not self.use_exponential_backoff:
            return float(self.retry_delay)

        # Exponential backoff: delay * (backoff_factor ^ attempt)
        delay = self.retry_delay * (self.backoff_factor**attempt)

        # Cap at max_retry_delay
        return min(delay, self.max_retry_delay)

    async def download_image(
        self, session: aiohttp.ClientSession, url: str, camera_id: str = None
    ) -> Optional[Image.Image]:
        """
        Download image from URL with comprehensive retry and optimization strategies

        Args:
            session: aiohttp client session
            url: Image URL
            camera_id: Optional camera ID for logging

        Returns:
            PIL Image object or None if failed
        """
        # Check cache first
        cached_image = self._get_cached_image(url)
        if cached_image is not None:
            return cached_image

        # Download with retries
        for attempt in range(self.max_retries):
            try:
                # Create timeout with both total and connection timeouts
                timeout = aiohttp.ClientTimeout(
                    total=self.timeout, connect=self.ssl_timeout, sock_read=self.timeout
                )

                log_prefix = f"[{camera_id}]" if camera_id else ""
                logger.info(
                    f"{log_prefix} Downloading image (attempt {attempt + 1}/{self.max_retries}): {url[:80]}..."
                )

                async with session.get(
                    url,
                    timeout=timeout,
                    allow_redirects=self.follow_redirects,
                    max_redirects=self.max_redirects,
                ) as response:

                    if response.status == 200:
                        # Read image data
                        image_data = await response.read()

                        # Validate data size
                        if len(image_data) < 1024:  # Less than 1KB likely invalid
                            logger.warning(
                                f"{log_prefix} Downloaded data too small: {len(image_data)} bytes"
                            )
                            continue

                        # Open image
                        image = Image.open(io.BytesIO(image_data))

                        # Validate image
                        if image.size[0] < 100 or image.size[1] < 100:
                            logger.warning(
                                f"{log_prefix} Image too small: {image.size}"
                            )
                            continue

                        logger.info(
                            f"{log_prefix} ‚úÖ Successfully downloaded: {len(image_data)} bytes, {image.size}"
                        )

                        # Cache the image
                        self._save_to_cache(url, image)

                        return image

                    elif response.status == 404:
                        logger.error(
                            f"{log_prefix} Image not found (404): {url[:80]}..."
                        )
                        return None  # Don't retry for 404

                    elif response.status >= 500:
                        logger.warning(
                            f"{log_prefix} Server error {response.status}, will retry"
                        )

                    else:
                        logger.warning(
                            f"{log_prefix} HTTP {response.status} for URL: {url[:80]}..."
                        )

            except asyncio.TimeoutError:
                retry_delay = self._calculate_retry_delay(attempt)
                logger.warning(
                    f"{log_prefix} ‚è∞ Timeout after {self.timeout}s "
                    f"(attempt {attempt + 1}/{self.max_retries}). "
                    f"Retrying in {retry_delay:.1f}s..."
                )

            except aiohttp.ClientError as e:
                # Network errors are expected and handled by retry logic
                logger.debug(f"{log_prefix} Connection error: {type(e).__name__}: {e}")

            except Exception as e:
                logger.error(f"{log_prefix} Unexpected error: {type(e).__name__}: {e}")

            # Retry delay with exponential backoff
            if attempt < self.max_retries - 1:
                retry_delay = self._calculate_retry_delay(attempt)
                await asyncio.sleep(retry_delay)

        # All retries failed
        logger.error(
            f"{log_prefix} ‚ùå Failed to download after {self.max_retries} attempts: {url[:80]}..."
        )
        return None

    def _create_connector(self) -> aiohttp.TCPConnector:
        """
        Create optimized TCP connector with connection pooling

        Returns:
            Configured TCPConnector
        """
        return aiohttp.TCPConnector(
            limit=self.pool_size,
            limit_per_host=self.pool_size,
            ttl_dns_cache=self.dns_cache_ttl,
            keepalive_timeout=self.keepalive_timeout,
            enable_cleanup_closed=True,
            force_close=False,
            ssl=self.verify_ssl,
        )

    async def download_batch(
        self, urls: List[Tuple[str, str]]
    ) -> Dict[str, Optional[Image.Image]]:
        """
        Download batch of images with optimized connection pooling

        Args:
            urls: List of (camera_id, url) tuples

        Returns:
            Dictionary mapping camera_id to Image or None
        """
        if not urls:
            return {}

        # Create connector and session
        connector = self._create_connector()
        headers = self._get_headers()

        logger.info(f"Starting batch download: {len(urls)} images")
        logger.info(
            f"Connection pool size: {self.pool_size}, Timeout: {self.timeout}s, Retries: {self.max_retries}"
        )

        async with aiohttp.ClientSession(
            connector=connector,
            headers=headers,
            trust_env=True,  # Use system proxy settings
        ) as session:

            # Download images (can be parallel or sequential based on config)
            tasks = [
                self.download_image(session, url, camera_id) for camera_id, url in urls
            ]
            results = await asyncio.gather(*tasks, return_exceptions=True)

            # Map results to camera IDs
            image_map = {}
            success_count = 0

            for (camera_id, url), result in zip(urls, results):
                if isinstance(result, Exception):
                    logger.error(
                        f"[{camera_id}] Exception: {type(result).__name__}: {result}"
                    )
                    image_map[camera_id] = None
                elif result is None:
                    image_map[camera_id] = None
                else:
                    image_map[camera_id] = result
                    success_count += 1

            logger.info(
                f"Batch download complete: {success_count}/{len(urls)} successful "
                f"({success_count/len(urls)*100:.1f}%)"
            )

            return image_map


class MetricsCalculator:
    """Calculate traffic metrics from detections"""

    def __init__(self, config: Dict[str, Any]):
        """
        Initialize metrics calculator

        Args:
            config: Metrics configuration dictionary
        """
        self.config = config
        self.intensity_threshold = config.get("intensity_threshold", 0.7)
        self.low_intensity_threshold = config.get("low_intensity_threshold", 0.3)
        self.occupancy_max_vehicles = config.get("occupancy_max_vehicles", 50)
        self.default_speed = config.get("default_speed_kmh", 20.0)
        self.min_speed = config.get("min_speed_kmh", 5.0)
        self.max_speed = config.get("max_speed_kmh", 80.0)

    def calculate(self, vehicle_count: int) -> TrafficMetrics:
        """
        Calculate traffic metrics from vehicle count

        Args:
            vehicle_count: Number of vehicles detected

        Returns:
            TrafficMetrics object
        """
        # Calculate intensity and occupancy (0.0-1.0)
        intensity = min(vehicle_count / self.occupancy_max_vehicles, 1.0)
        occupancy = intensity

        # Estimate speed based on congestion
        if intensity >= self.intensity_threshold:
            congestion_level = "congested"
            average_speed = self.min_speed
        elif intensity >= self.low_intensity_threshold:
            congestion_level = "moderate"
            # Linear interpolation between max and min speed
            speed_range = self.max_speed - self.min_speed
            speed_factor = (self.intensity_threshold - intensity) / (
                self.intensity_threshold - self.low_intensity_threshold
            )
            average_speed = self.min_speed + (speed_range * speed_factor)
        else:
            congestion_level = "free"
            # Add realistic speed variance even in free-flow conditions
            # This prevents all cameras from having identical speeds
            import random

            variance = random.uniform(-8, 12)  # -10% to +15% variance
            average_speed = max(
                self.min_speed, min(self.max_speed + variance, self.max_speed * 1.15)
            )

        return TrafficMetrics(
            vehicle_count=vehicle_count,
            intensity=round(intensity, 2),
            occupancy=round(occupancy, 2),
            average_speed=round(average_speed, 1),
            congestion_level=congestion_level,
        )


class NGSILDEntityGenerator:
    """Generate NGSI-LD entities from analysis results"""

    @staticmethod
    def create_accident_entity(
        camera_id: str,
        location: Dict[str, Any],
        confidence: float,
        severity: str,
        timestamp: str,
        detection_index: int = 0,
    ) -> Dict[str, Any]:
        """
        Create Accident NGSI-LD entity

        Args:
            camera_id: Camera identifier
            location: Location GeoJSON (Point)
            confidence: Detection confidence (0-1)
            severity: Severity level (minor, moderate, severe)
            timestamp: ISO 8601 timestamp
            detection_index: Index for unique ID when multiple accidents at same camera

        Returns:
            NGSI-LD Accident entity dictionary
        """
        # Generate unique ID
        ts_clean = (
            timestamp.replace(":", "")
            .replace("-", "")
            .replace(".", "")
            .replace("Z", "")
        )
        entity_id = f"urn:ngsi-ld:Accident:{camera_id}-{ts_clean}-{detection_index}"

        entity = {
            "@context": ["https://uri.etsi.org/ngsi-ld/v1/ngsi-ld-core-context.jsonld"],
            "id": entity_id,
            "type": "Accident",
            "location": {"type": "GeoProperty", "value": location},
            "accidentDate": {"type": "Property", "value": timestamp},
            "severity": {"type": "Property", "value": severity},
            "confidence": {"type": "Property", "value": round(confidence, 3)},
            "status": {"type": "Property", "value": "detected"},
            "detectedBy": {
                "type": "Relationship",
                "object": f"urn:ngsi-ld:Camera:{camera_id}",
            },
            "accidentType": {"type": "Property", "value": "traffic_accident"},
            "source": {"type": "Property", "value": "DETR-CV-Analysis"},
        }

        return entity

    @staticmethod
    def create_item_flow_observed(
        camera_id: str,
        location: Dict[str, Any],
        metrics: TrafficMetrics,
        timestamp: str,
        detections: Optional[List[Detection]] = None,
    ) -> Dict[str, Any]:
        """
        Create ItemFlowObserved NGSI-LD entity

        Args:
            camera_id: Camera identifier
            location: Location GeoJSON (Point)
            metrics: Traffic metrics
            timestamp: ISO 8601 timestamp
            detections: Optional list of detections

        Returns:
            NGSI-LD entity dictionary
        """
        entity = {
            "@context": [
                "https://uri.etsi.org/ngsi-ld/v1/ngsi-ld-core-context.jsonld",
                "https://smartdatamodels.org/context.jsonld",
            ],
            "id": f"urn:ngsi-ld:ItemFlowObserved:{camera_id}-{timestamp.replace(':', '').replace('-', '').replace('.', '')}",
            "type": "ItemFlowObserved",
            "refDevice": {
                "type": "Relationship",
                "object": f"urn:ngsi-ld:Camera:{camera_id}",
            },
            "location": {"type": "GeoProperty", "value": location},
            "intensity": {
                "type": "Property",
                "value": metrics.intensity,
                "observedAt": timestamp,
            },
            "occupancy": {
                "type": "Property",
                "value": metrics.occupancy,
                "observedAt": timestamp,
            },
            "averageSpeed": {
                "type": "Property",
                "value": metrics.average_speed,
                "unitCode": "KMH",
                "observedAt": timestamp,
            },
            "vehicleCount": {
                "type": "Property",
                "value": metrics.vehicle_count,
                "observedAt": timestamp,
            },
            "congestionLevel": {
                "type": "Property",
                "value": metrics.congestion_level,
                "observedAt": timestamp,
            },
        }

        # Add detection details if provided
        if detections:
            entity["detectionDetails"] = {
                "type": "Property",
                "value": {"total_detections": len(detections), "classes": {}},
            }

            # Count by class
            class_counts = {}
            for det in detections:
                class_counts[det.class_name] = class_counts.get(det.class_name, 0) + 1

            entity["detectionDetails"]["value"]["classes"] = class_counts

        return entity


class CVAnalysisAgent:
    """Main CV analysis agent"""

    def __init__(self, config_path: str = "config/cv_config.yaml"):
        """
        Initialize CV analysis agent

        Args:
            config_path: Path to configuration file
        """
        self.config_loader = CVConfig(config_path)
        self.config = self.config_loader  # Alias for backward compatibility

        # Get full cv_analysis config for ImageDownloader
        cv_analysis_config = self.config_loader.config.get("cv_analysis", {})

        self.detector = YOLOXDetector(self.config_loader.get_model_config())
        self.downloader = ImageDownloader(cv_analysis_config)
        self.metrics_calculator = MetricsCalculator(
            self.config_loader.get_metrics_config()
        )
        self.vehicle_classes = set(self.config_loader.get_vehicle_classes())
        self.person_classes = set(self.config_loader.get_person_classes())

        # Get class IDs for filtering
        self.vehicle_class_ids = {
            YOLOXDetector.CLASS_NAME_TO_ID.get(name, -1)
            for name in self.vehicle_classes
        }
        self.person_class_ids = {
            YOLOXDetector.CLASS_NAME_TO_ID.get(name, -1) for name in self.person_classes
        }

        # Initialize accident detector if enabled
        accident_config = cv_analysis_config.get("accident_detection", {})
        if accident_config.get("enabled", False):
            accident_model_config = accident_config.get("model", {})
            accident_model_config["severity_thresholds"] = accident_config.get(
                "severity_thresholds", {}
            )
            self.accident_detector = AccidentDetector(accident_model_config)

            if self.accident_detector.is_enabled():
                logger.info("‚úÖ Accident detection enabled")
            else:
                logger.warning("‚ö†Ô∏è Accident detection configured but model not loaded")
                self.accident_detector = None
        else:
            self.accident_detector = None
            logger.info("‚ÑπÔ∏è Accident detection disabled in config")

        # Initialize detected accidents list
        self._detected_accidents: List[Dict[str, Any]] = []

        # MongoDB helper (optional, non-blocking)
        self._mongodb_helper = None
        if MONGODB_AVAILABLE:
            try:
                self._mongodb_helper = get_mongodb_helper()
                if self._mongodb_helper and self._mongodb_helper.enabled:
                    logger.info("‚úÖ MongoDB publishing enabled for CV agent")
            except Exception as e:
                logger.debug(f"MongoDB initialization failed (non-critical): {e}")

    def analyze_image(
        self, camera_id: str, image: Image.Image, image_url: str = ""
    ) -> ImageAnalysisResult:
        """
        Analyze single image

        Args:
            camera_id: Camera identifier
            image: PIL Image object
            image_url: Image URL (for reference)

        Returns:
            ImageAnalysisResult object
        """
        start_time = time.time()
        timestamp = datetime.utcnow().isoformat() + "Z"

        try:
            # Perform vehicle detection
            detections = self.detector.detect(image)

            # Filter and count vehicles and persons
            vehicle_detections = [
                d for d in detections if d.class_id in self.vehicle_class_ids
            ]
            person_detections = [
                d for d in detections if d.class_id in self.person_class_ids
            ]

            vehicle_count = len(vehicle_detections)
            person_count = len(person_detections)

            # Perform accident detection if enabled
            accident_detections = []
            if self.accident_detector:
                accident_detections = self.accident_detector.detect(image)

                # Log accident detections (INFO level to avoid warnings in log)
                if accident_detections:
                    logger.info(f"üö® ACCIDENT DETECTED at camera {camera_id}!")
                    for acc_det in accident_detections:
                        severity = self.accident_detector.estimate_severity(acc_det)
                        logger.info(
                            f"   - Severity: {severity.upper()} (confidence: {acc_det.confidence:.2f})"
                        )

            processing_time = time.time() - start_time

            status = (
                DetectionStatus.SUCCESS if detections else DetectionStatus.NO_DETECTIONS
            )

            result = ImageAnalysisResult(
                camera_id=camera_id,
                status=status,
                timestamp=timestamp,
                detections=detections,
                vehicle_count=vehicle_count,
                person_count=person_count,
                processing_time=processing_time,
                image_url=image_url,
            )

            # Add accident detection results to result metadata
            if accident_detections:
                result.metadata = result.metadata or {}
                result.metadata["accidents"] = [
                    {
                        "class": det.class_name,
                        "confidence": det.confidence,
                        "severity": self.accident_detector.estimate_severity(det),
                        "bbox": det.bbox,
                    }
                    for det in accident_detections
                ]
                logger.info(
                    f"üìù Set metadata.accidents for camera {camera_id}: {len(result.metadata['accidents'])} accidents"
                )

            return result

        except Exception as e:
            logger.error(f"Analysis failed for {camera_id}: {e}")
            processing_time = time.time() - start_time

            return ImageAnalysisResult(
                camera_id=camera_id,
                status=DetectionStatus.FAILED,
                timestamp=timestamp,
                processing_time=processing_time,
                error_message=str(e),
                image_url=image_url,
            )

    async def process_cameras(
        self, cameras: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """
        Process batch of cameras

        Args:
            cameras: List of camera dictionaries with 'id', 'image_url_x4' (or 'imageSnapshot' fallback), 'location'
                    Note: 'image_url_x4' should be refreshed by image_refresh_agent to have current timestamp

        Returns:
            List of NGSI-LD ItemFlowObserved entities
        """
        batch_size = self.config_loader.get_batch_size()
        all_entities = []

        # Collect detected accidents for saving to accidents.json
        self._detected_accidents = []
        
        # Get real-time publisher for immediate Stellio push
        realtime_publisher = get_realtime_publisher()
        
        # Process in batches
        for i in range(0, len(cameras), batch_size):
            batch = cameras[i:i + batch_size]
            batch_num = i // batch_size + 1
            total_batches = (len(cameras) + batch_size - 1) // batch_size
            logger.info(f"Processing batch {batch_num}/{total_batches} ({len(batch)} cameras)")
            
            # Entities detected in this batch (for real-time push)
            batch_entities = []
            batch_accidents = []
            

            # Download images - use image_url_x4 (refreshed by image_refresh_agent)
            urls = [
                (cam["id"], cam.get("image_url_x4", cam.get("imageSnapshot", "")))
                for cam in batch
            ]
            images = await self.downloader.download_batch(urls)

            # Analyze each image
            for camera in batch:
                camera_id = camera["id"]
                image = images.get(camera_id)

                if image is None:
                    logger.warning(f"Failed to download image for {camera_id}")
                    continue

                # Analyze image
                result = self.analyze_image(
                    camera_id=camera_id,
                    image=image,
                    image_url=camera.get(
                        "image_url_x4", camera.get("imageSnapshot", "")
                    ),
                )

                if (
                    result.status == DetectionStatus.SUCCESS
                    or result.status == DetectionStatus.NO_DETECTIONS
                ):
                    # Calculate metrics
                    metrics = self.metrics_calculator.calculate(result.vehicle_count)

                    # Build location from camera data
                    # Check if camera has NGSI-LD location or raw lat/lon
                    if "location" in camera and camera["location"]:
                        location = camera["location"]
                    elif "latitude" in camera and "longitude" in camera:
                        # Build GeoJSON from latitude/longitude
                        location = {
                            "type": "Point",
                            "coordinates": [
                                float(camera["longitude"]),
                                float(camera["latitude"]),
                            ],
                        }
                    else:
                        location = {}

                    # Create NGSI-LD entity
                    entity = NGSILDEntityGenerator.create_item_flow_observed(
                        camera_id=camera_id,
                        location=location,
                        metrics=metrics,
                        timestamp=result.timestamp,
                        detections=(
                            result.detections
                            if self.config_loader.get_output_config().get(
                                "include_detections"
                            )
                            else None
                        ),
                    )

                    all_entities.append(entity)
                    batch_entities.append(entity)
                    

                    # Create Accident entities if accidents detected
                    # Debug: log metadata state
                    if result.metadata:
                        logger.debug(
                            f"Camera {camera_id} metadata keys: {list(result.metadata.keys())}"
                        )

                    if result.metadata and "accidents" in result.metadata:
                        accidents = result.metadata["accidents"]
                        for idx, acc in enumerate(accidents):
                            accident_entity = (
                                NGSILDEntityGenerator.create_accident_entity(
                                    camera_id=camera_id,
                                    location=location,
                                    confidence=acc["confidence"],
                                    severity=acc["severity"],
                                    timestamp=result.timestamp,
                                    detection_index=idx,
                                )
                            )
                            self._detected_accidents.append(accident_entity)
                            batch_accidents.append(accident_entity)
                            logger.info(f"üö® Created Accident entity: {accident_entity['id']} (severity: {acc['severity']})")
                    
                    logger.info(
                        f"Processed {camera_id}: {result.vehicle_count} vehicles, "
                        f"intensity={metrics.intensity}, speed={metrics.average_speed} km/h"
                    )
            
            # üöÄ REAL-TIME PUSH: Push batch entities to Stellio IMMEDIATELY after each batch
            if batch_entities:
                realtime_publisher.publish_entities_batch(batch_entities, "ItemFlowObserved")
            
            # üö® REAL-TIME PUSH: Push accidents to Stellio IMMEDIATELY
            if batch_accidents:
                realtime_publisher.publish_entities_batch(batch_accidents, "Accident")
                # Also save accidents incrementally to file
                self._save_accidents_incremental(batch_accidents)
        
        # Log summary of detected accidents
        if self._detected_accidents:
            logger.info(
                f"üìä Total accidents detected: {len(self._detected_accidents)} across all cameras"
            )

        return all_entities

    
    def _save_accidents_incremental(self, new_accidents: List[Dict[str, Any]], output_file: str = 'data/accidents.json') -> None:
        """
        Incrementally save new accidents to file (append with deduplication).
        Called after each batch for real-time persistence.
        """
        if not new_accidents:
            return
            
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # Load existing
        existing = []
        if output_path.exists():
            try:
                with open(output_file, 'r', encoding='utf-8') as f:
                    existing = json.load(f)
            except:
                existing = []
        
        # Merge with dedup
        existing_ids = {acc.get('id') for acc in existing}
        for acc in new_accidents:
            if acc.get('id') not in existing_ids:
                existing.append(acc)
                existing_ids.add(acc.get('id'))
        
        # Save
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(existing, f, indent=2, ensure_ascii=False)
        
        logger.info(f"üíæ Saved {len(new_accidents)} new accidents to {output_file} (total: {len(existing)})")
    
    def save_observations(self, entities: List[Dict[str, Any]], output_file: Optional[str] = None) -> None:
        """
        Save observations to JSON file

        Args:
            entities: List of NGSI-LD entities
            output_file: Output file path (optional, uses config if not provided)
        """
        if output_file is None:
            output_file = self.config_loader.get_output_config().get(
                "file", "data/observations.json"
            )

        # Ensure output directory exists
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)

        # Save to file
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(entities, f, indent=2, ensure_ascii=False)

        logger.info(f"Saved {len(entities)} observations to {output_file}")

        # Optionally publish to MongoDB (non-blocking)
        if self._mongodb_helper and self._mongodb_helper.enabled and entities:
            try:
                success, failed = self._mongodb_helper.insert_entities_batch(entities)
                if success > 0:
                    logger.info(
                        f"‚úÖ Published {success} ItemFlowObserved entities to MongoDB"
                    )
                if failed > 0:
                    logger.warning(f"‚ö†Ô∏è Failed to publish {failed} entities to MongoDB")
            except Exception as e:
                logger.warning(f"MongoDB publishing failed (non-critical): {e}")

    def save_accidents(self, output_file: str = "data/accidents.json") -> None:
        """
        Save detected accidents to JSON file for downstream processing.

        
        This method APPENDS accidents detected during process_cameras() to a JSON file.
        Existing accidents are preserved and new ones are added with deduplication by ID.
        The file will be picked up by the workflow for validation and publishing to Stellio.
        
        Args:
            output_file: Output file path (default: 'data/accidents.json')
        """
        new_accidents = getattr(self, '_detected_accidents', [])
        
        # Ensure output directory exists
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # Load existing accidents to append (not overwrite)
        existing_accidents = []
        if output_path.exists():
            try:
                with open(output_file, 'r', encoding='utf-8') as f:
                    existing_accidents = json.load(f)
                logger.info(f"üìÇ Loaded {len(existing_accidents)} existing accidents from {output_file}")
            except (json.JSONDecodeError, Exception) as e:
                logger.warning(f"Could not load existing accidents: {e}, starting fresh")
                existing_accidents = []
        
        # Merge with deduplication by ID
        existing_ids = {acc.get('id') for acc in existing_accidents}
        merged_accidents = existing_accidents.copy()
        
        new_count = 0
        for acc in new_accidents:
            if acc.get('id') not in existing_ids:
                merged_accidents.append(acc)
                existing_ids.add(acc.get('id'))
                new_count += 1
        
        # Save merged accidents to file
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(merged_accidents, f, indent=2, ensure_ascii=False)
        
        logger.info(f"üíæ Saved {len(merged_accidents)} accident entities to {output_file} (+{new_count} new)")
        

        # Optionally publish accidents to MongoDB (non-blocking)
        if self._mongodb_helper and self._mongodb_helper.enabled and accidents:
            try:
                success, failed = self._mongodb_helper.insert_entities_batch(accidents)
                if success > 0:
                    logger.info(f"‚úÖ Published {success} Accident entities to MongoDB")
                if failed > 0:
                    logger.warning(
                        f"‚ö†Ô∏è Failed to publish {failed} accident entities to MongoDB"
                    )
            except Exception as e:
                logger.warning(f"MongoDB publishing failed (non-critical): {e}")

    async def process_citizen_reports(self) -> int:
        """
        AI Verification Loop for Citizen Reports.

        Queries Stellio for unverified CitizenObservation entities (aiVerified=false),
        downloads images, runs YOLOX detection, compares AI results vs user reports,
        and PATCHES Stellio with verification results.

        This function is designed to run periodically (e.g., every 30 seconds) as a
        background task, separate from camera processing.

        Returns:
            Number of reports processed

        Flow:
            1. Query Stellio for type=CitizenObservation&q=aiVerified==false
            2. Download image from imageSnapshot property
            3. Run YOLOX object detection
            4. For accident reports: Also run AccidentDetector
            5. Compare AI detections vs user reportType using verification rules
            6. Calculate confidence score (0.0-1.0)
            7. PATCH Stellio with:
               - aiVerified: true
               - aiConfidence: 0.X
               - status: "verified" or "rejected"
               - aiMetadata: {detections, vehicle_count, etc.}
        """
        if not self.config.citizen_verification_enabled:
            logger.debug("Citizen verification disabled in config")
            return 0

        logger.info("üîç Starting citizen report verification cycle")

        try:
            from urllib.parse import quote

            import requests

            # Step 1: Query Stellio for unverified reports
            stellio_url = self.config.citizen_verification_stellio_url
            query = self.config.citizen_verification_query
            max_batch = self.config.citizen_verification_max_batch

            url = f"{stellio_url}/ngsi-ld/v1/entities?{query}&limit={max_batch}"

            response = requests.get(
                url, headers={"Accept": "application/ld+json"}, timeout=30
            )

            if response.status_code != 200:
                logger.warning(f"Stellio query failed: {response.status_code}")
                return 0

            reports = response.json()

            if not reports:
                logger.debug("No unverified citizen reports found")
                return 0

            logger.info(f"üìã Found {len(reports)} unverified reports")

            # Step 2: Process each report
            verified_count = 0

            for report in reports:
                try:
                    entity_id = report["id"]
                    report_type = report.get("category", {}).get("value", "other")
                    image_url = report.get("imageSnapshot", {}).get("value")

                    if not image_url:
                        logger.warning(f"Report {entity_id} has no image, skipping")
                        continue

                    logger.info(f"üîé Verifying {entity_id} (type: {report_type})")

                    # Step 3: Download or load image
                    # Support both HTTP URLs and local file:// URLs for testing
                    if image_url.startswith("file://"):
                        # Local file path
                        local_path = image_url.replace("file://", "").replace(
                            "/", os.sep
                        )
                        if not os.path.exists(local_path):
                            logger.warning(f"Local image file not found: {local_path}")
                            continue
                        image = Image.open(local_path)
                    else:
                        # HTTP(S) URL - download from remote server
                        async with aiohttp.ClientSession() as session:
                            async with session.get(
                                image_url, timeout=30
                            ) as img_response:
                                if img_response.status != 200:
                                    logger.warning(
                                        f"Failed to download image: {img_response.status}"
                                    )
                                    continue

                                image_bytes = await img_response.read()
                                image = Image.open(io.BytesIO(image_bytes))

                    # Step 4: Run YOLOX detection (synchronous method)
                    result = self.analyze_image(
                        camera_id=entity_id, image_url=image_url, image=image
                    )

                    if result.status != DetectionStatus.SUCCESS:
                        logger.warning(
                            f"Detection failed for {entity_id}: {result.error_message}"
                        )
                        continue

                    # Step 5: Get verification rules for this report type
                    rules = self.config.citizen_verification_rules.get(
                        report_type,
                        self.config.citizen_verification_rules.get("other", {}),
                    )

                    verification_strategy = rules.get("verification_strategy", "ai")

                    if verification_strategy == "manual":
                        logger.info(
                            f"Report type '{report_type}' requires manual verification, skipping"
                        )
                        continue

                    # Step 6: Calculate verification score
                    required_objects = rules.get("required_objects", [])
                    min_count = rules.get("min_count", 0)
                    use_accident_model = rules.get("use_accident_model", False)

                    # Count detected objects matching required classes
                    detected_classes = [d.class_name for d in result.detections]
                    matching_objects = [
                        obj for obj in detected_classes if obj in required_objects
                    ]
                    object_match_score = 1.0 if len(matching_objects) > 0 else 0.0

                    # Check vehicle count threshold
                    count_match_score = (
                        1.0 if result.vehicle_count >= min_count else 0.0
                    )

                    # Average detection confidence
                    avg_confidence = (
                        sum(d.confidence for d in result.detections)
                        / len(result.detections)
                        if result.detections
                        else 0.0
                    )

                    # Special handling for accident reports
                    accident_score = 0.0
                    accident_detected = False

                    if use_accident_model and self.accident_detector:
                        # Check metadata for accident detection results
                        if result.metadata and "accidents" in result.metadata:
                            accidents = result.metadata["accidents"]
                            if accidents:
                                accident_detected = True
                                accident_score = max(a["confidence"] for a in accidents)
                                logger.info(
                                    f"üö® Accident model detected accident: confidence={accident_score:.2f}"
                                )

                    # Calculate weighted confidence score
                    if use_accident_model and self.accident_detector:
                        # For accident reports, prioritize accident model
                        confidence = (
                            accident_score * 0.7  # Accident detection is primary
                            + object_match_score * 0.2
                            + avg_confidence * 0.1
                        )
                    else:
                        # Standard scoring from config
                        weights = self.config.citizen_verification_scoring
                        confidence = (
                            object_match_score * weights.get("object_match_weight", 0.6)
                            + count_match_score * weights.get("count_match_weight", 0.3)
                            + avg_confidence * weights.get("confidence_weight", 0.1)
                        )

                    # Determine verification status
                    threshold = rules.get("confidence_threshold", 0.5)
                    is_verified = confidence >= threshold
                    status = "verified" if is_verified else "rejected"

                    logger.info(
                        f"{'‚úÖ' if is_verified else '‚ùå'} Verification result: "
                        f"confidence={confidence:.2f}, status={status}"
                    )

                    # Step 7: Build AI metadata
                    ai_metadata = {
                        "vehicle_count": result.vehicle_count,
                        "person_count": result.person_count,
                        "detected_classes": list(set(detected_classes)),
                        "matching_objects": matching_objects,
                        "avg_detection_confidence": avg_confidence,
                        "verification_timestamp": datetime.utcnow().isoformat() + "Z",
                        "processing_time": result.processing_time,
                    }

                    if use_accident_model and accident_detected:
                        ai_metadata["accident_detected"] = True
                        ai_metadata["accident_confidence"] = accident_score

                    # Step 8: PATCH Stellio entity
                    if self.config.citizen_verification_update_patch_stellio:
                        patch_data = {
                            "@context": [
                                "https://uri.etsi.org/ngsi-ld/v1/ngsi-ld-core-context.jsonld"
                            ],
                            "aiVerified": {"type": "Property", "value": True},
                            "aiConfidence": {
                                "type": "Property",
                                "value": round(confidence, 3),
                            },
                            "aiMetadata": {"type": "Property", "value": ai_metadata},
                        }

                        if self.config.citizen_verification_update_set_verified_status:
                            patch_data["status"] = {"type": "Property", "value": status}

                        patch_url = f"{stellio_url}/ngsi-ld/v1/entities/{quote(entity_id, safe='')}/attrs"

                        patch_response = requests.patch(
                            patch_url,
                            json=patch_data,
                            headers={"Content-Type": "application/ld+json"},
                            timeout=30,
                        )

                        if patch_response.status_code in [200, 204]:
                            logger.info(f"‚úÖ Updated {entity_id} in Stellio")
                            verified_count += 1
                        else:
                            logger.error(
                                f"‚ùå Failed to PATCH Stellio: {patch_response.status_code} "
                                f"{patch_response.text}"
                            )

                except Exception as e:
                    logger.error(
                        f"Error processing report {entity_id}: {e}", exc_info=True
                    )
                    continue

            logger.info(f"‚úÖ Verified {verified_count}/{len(reports)} citizen reports")
            return verified_count

        except Exception as e:
            logger.error(f"Citizen verification cycle failed: {e}", exc_info=True)
            return 0

    async def run(
        self, input_file: str, output_file: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """
        Run CV analysis on cameras from input file

        Args:
            input_file: Path to cameras JSON file
            output_file: Optional output file path

        Returns:
            List of NGSI-LD entities
        """
        # Load cameras
        with open(input_file, "r", encoding="utf-8") as f:
            data = json.load(f)

        # Handle both array and object with 'cameras' key
        if isinstance(data, list):
            cameras = data
        else:
            cameras = data.get("cameras", [])

        logger.info(f"Loaded {len(cameras)} cameras from {input_file}")

        # Process cameras
        start_time = time.time()
        entities = await self.process_cameras(cameras)
        processing_time = time.time() - start_time

        logger.info(
            f"Processed {len(cameras)} cameras in {processing_time:.2f}s "
            f"({processing_time/len(cameras):.2f}s/camera)"
        )

        # Save observations
        self.save_observations(entities, output_file)

        # Save detected accidents to data/accidents.json for downstream workflow
        self.save_accidents("data/accidents.json")

        return entities


def main(config: Optional[Dict[str, Any]] = None):
    """Main entry point

    Args:
        config: Optional workflow agent config (from orchestrator)
    """
    import sys
    import platform
    
    # Fix Windows asyncio event loop issue with aiohttp
    if platform.system() == 'Windows':
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    
    # Parse command line arguments or use config
    config_path = "config/cv_config.yaml"
    input_file = "data/cameras_updated.json"
    output_file = None

    # Use config from orchestrator if provided
    if config:
        config_path = config.get("config_path", config_path)
        input_file = config.get("input_file", input_file)
        output_file = config.get("output_file", output_file)
    elif len(sys.argv) > 1:
        input_file = sys.argv[1]
    if len(sys.argv) > 2:
        output_file = sys.argv[2]
    if len(sys.argv) > 3:
        config_path = sys.argv[3]

    # Create and run agent
    agent = CVAnalysisAgent(config_path)
    entities = asyncio.run(agent.run(input_file, output_file))

    print(f"Generated {len(entities)} ItemFlowObserved entities")


if __name__ == "__main__":
    main()
